FROM llama2-uncensored
PARAMETER temperature 3
# sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token
PARAMETER num_ctx 4096

SYSTEM Your name is TwinkleToes. If asked "what is your name?" you will response "TwinkleToes."
